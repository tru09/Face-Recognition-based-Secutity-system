{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pred_np_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9BMofxD62PE"
      },
      "source": [
        "import os\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkNaa6AL5yBH"
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "cls=-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JloxReHc6_CS"
      },
      "source": [
        "for name in os.listdir(\"/content/drive/MyDrive/training\"):\n",
        "  cls+=1\n",
        "  i=0\n",
        "  for img in os.listdir(os.path.join(\"/content/drive/MyDrive/training\",name)):\n",
        "    img = imageio.imread(os.path.join(\"/content/drive/MyDrive/training\",name,img))\n",
        "    resized_image = cv2.resize(img, (128,128)) \n",
        "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
        "    if i<175:\n",
        "      X_train.append(gray)\n",
        "      y_train.append(cls)\n",
        "    else:\n",
        "      X_test.append(gray)\n",
        "      y_test.append(cls)\n",
        "    i+=1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icvfy5jn8b_H"
      },
      "source": [
        "X_train = np.array(X_train,dtype='float32')/255\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test,dtype='float32')/255\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka749uiJAQTR",
        "outputId": "facb617d-653b-484a-86c7-b42cf31a212e"
      },
      "source": [
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(525, 128, 128) (525,)\n",
            "(76, 128, 128) (76,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bThNVOyNg9zg",
        "outputId": "193b6a8f-1662-421f-96fe-31003ac5b0e4"
      },
      "source": [
        "print(np.any(np.isnan(X_test)))\r\n",
        "print(np.any(np.isnan(y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwpDSwnL6--p"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout,BatchNormalization,Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.utils import np_utils\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXEZaANK9OFl"
      },
      "source": [
        "x_train, x_valid, y_train, y_valid= train_test_split(X_train, y_train, test_size=0.2, random_state=1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyAWpnldBhQ_",
        "outputId": "46798105-609b-4423-d9ef-13367fe4504d"
      },
      "source": [
        "print(x_train.shape, x_valid.shape, y_train.shape, y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(420, 128, 128) (105, 128, 128) (420,) (105,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M4Z6C8i9OBs"
      },
      "source": [
        "im_rows=128\n",
        "im_cols=128\n",
        "batch_size=265\n",
        "im_shape=(im_rows, im_cols,1)\n",
        "\n",
        "#change the size of images\n",
        "x_train = x_train.reshape(x_train.shape[0], *im_shape)\n",
        "x_test = X_test.reshape(X_test.shape[0], *im_shape)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], *im_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYv7vO-MDAiD",
        "outputId": "7eb18946-1cbb-4513-edc5-d19a700f9644"
      },
      "source": [
        "print('x_train shape: {}'.format(x_train.shape))\n",
        "print('x_test shape: {}'.format(x_test.shape))\n",
        "print('x_valid shape: {}'.format(x_valid.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (420, 128, 128, 1)\n",
            "x_test shape: (76, 128, 128, 1)\n",
            "x_valid shape: (105, 128, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LerWN1A8QW5o",
        "outputId": "86763a0d-0f48-4ff4-fbcb-4e62b04b7ec0"
      },
      "source": [
        "print(type(x_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaakiVPicdo5"
      },
      "source": [
        "# from keras.utils import to_categorical\r\n",
        "# y_train=to_categorical(y_train)\r\n",
        "# y_test=to_categorical(y_test)\r\n",
        "# y_valid=to_categorical(y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyxzsOo09N-R"
      },
      "source": [
        "#used model\n",
        "cnn_model= Sequential([\n",
        "    Conv2D(filters=36, kernel_size=3, activation='relu', input_shape= im_shape),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Conv2D(filters=54, kernel_size=2, activation='relu'),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu'),\n",
        "    #20 is the number of outputs\n",
        "    Dense(2, activation='softmax')  \n",
        "])\n",
        "\n",
        "cnn_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',#'categorical_crossentropy',\n",
        "    optimizer=Adam(lr=0.0001),#Adam(lr=0.001)\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR8IDxaebuNu"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(128,128,1)))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(64, (1, 1)))\n",
        "model.add(Dropout(0.2))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(64, (1, 1)))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32))\n",
        "model.add(Dense(3))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH8cgfur9N5s",
        "outputId": "9dde3ee3-f9e2-4ede-d49b-06885e6cac63"
      },
      "source": [
        "history=model.fit(\n",
        "    np.array(x_train), np.array(y_train),\n",
        "    batch_size=32,\n",
        "    epochs=25,\n",
        "    shuffle=True,\n",
        "    validation_data=(np.array(x_valid),np.array(y_valid)),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "14/14 [==============================] - 2s 133ms/step - loss: 4.0251 - accuracy: 0.7295 - val_loss: 2.3733 - val_accuracy: 0.2952\n",
            "Epoch 2/25\n",
            "14/14 [==============================] - 2s 122ms/step - loss: 0.3370 - accuracy: 0.9858 - val_loss: 6.2437 - val_accuracy: 0.2952\n",
            "Epoch 3/25\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 4.0189 - val_accuracy: 0.2952\n",
            "Epoch 4/25\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.9511 - val_accuracy: 0.2952\n",
            "Epoch 5/25\n",
            "14/14 [==============================] - 2s 120ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.2425 - val_accuracy: 0.3905\n",
            "Epoch 6/25\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7285 - val_accuracy: 0.5048\n",
            "Epoch 7/25\n",
            "14/14 [==============================] - 2s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3351 - val_accuracy: 0.5524\n",
            "Epoch 8/25\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.9991 - val_accuracy: 0.5905\n",
            "Epoch 9/25\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.6000\n",
            "Epoch 10/25\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.6286\n",
            "Epoch 11/25\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.8286\n",
            "Epoch 12/25\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9810\n",
            "Epoch 13/25\n",
            "14/14 [==============================] - 2s 121ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "14/14 [==============================] - 2s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "14/14 [==============================] - 2s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "14/14 [==============================] - 2s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "14/14 [==============================] - 2s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "14/14 [==============================] - 2s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "14/14 [==============================] - 2s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.4717e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "14/14 [==============================] - 2s 124ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.2671e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "14/14 [==============================] - 2s 123ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.5444e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "14/14 [==============================] - 2s 122ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.1065e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "14/14 [==============================] - 2s 131ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.3333e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "14/14 [==============================] - 2s 123ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6038e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "14/14 [==============================] - 2s 123ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 7.9340e-06 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_omzzuxk9N2c",
        "outputId": "270d5fb7-20ef-44af-a0f5-65adb0e6b536"
      },
      "source": [
        "scor = model.evaluate( np.array(x_test),  np.array(y_test), verbose=0)\n",
        "\n",
        "print('test los {:.4f}'.format(scor[0]))\n",
        "print('test acc {:.4f}'.format(scor[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test los 0.0000\n",
            "test acc 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EGZzaro9NzL",
        "outputId": "26066042-9653-4363-f846-4b35ae4c0692"
      },
      "source": [
        "image = imageio.imread(\"/content/drive/MyDrive/training/Vasudev/Vasudev-21.png\")\r\n",
        "#image = imageio.imread(\"/content/drive/MyDrive/training/vishvesh/vishvesh-124.png\")\r\n",
        "#image = imageio.imread(\"/content/drive/MyDrive/training/shashank/shashank-121.png\")\r\n",
        "\r\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
        "resized_img = cv2.resize(gray,(128,128))\r\n",
        "img = asarray(gray)/255\r\n",
        "img = np.resize(img,(128,128,1))\r\n",
        "img = img.reshape(-1,128,128,1)\r\n",
        "pred = model.predict(img)\r\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.7645629e-20 1.0000000e+00 1.2020313e-16]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0GY_lN49NvM",
        "outputId": "a3bf084a-715d-411e-c39b-a2eabde0a76e"
      },
      "source": [
        "ynew = model.predict_classes(x_test)\n",
        "\n",
        "\n",
        "Acc=accuracy_score(y_test, ynew)\n",
        "print(\"accuracy : \")\n",
        "print(Acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy : \n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8j_wAp_9Nra"
      },
      "source": [
        "model.save('drive/MyDrive/model_np3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyyU7dEDC8-I"
      },
      "source": [
        "from tensorflow.keras.models import load_model\r\n",
        "cnn_model = load_model(\"/content/drive/MyDrive/model_np5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWW8ieVesaA5"
      },
      "source": [
        "import cv2\r\n",
        "import imageio\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uWRmyNPseP_"
      },
      "source": [
        "#image = imageio.imread('ghg.jpg')\r\n",
        "image = imageio.imread(\"drive/MyDrive/training/shashank/shashank-19.png\")\r\n",
        "image = imageio.imread(\"drive/MyDrive/training/vishvesh/vishvesh-100.png\")\r\n",
        "image = imageio.imread(\"drive/MyDrive/training/Vasudev/Vasudev-200.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdHmGqGzd_xM"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY74TE3W8S_f"
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ztf5czZdm9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a32ca76-01c0-449d-83a4-ea9f2f20b685"
      },
      "source": [
        "image = cv2.imread('ghg.jpg')\n",
        "resized_img = cv2.resize(image,(128,128))\n",
        "gray = cv2.cvtColor(resized_img,cv2.COLOR_BGR2GRAY)\n",
        "img = np.reshape(gray,(-1,128,128,1))\n",
        "img = np.array(img)/255\n",
        "pred = model.predict(img)\n",
        "print(pred[0].argmax())\n",
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "[[5.9617494e-05 9.9994040e-01 9.9995061e-11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "Xnsumrngg0ta",
        "outputId": "1f0b106b-0647-4e78-e300-45e07851e97f"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(gray)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7FB3246B5C88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}